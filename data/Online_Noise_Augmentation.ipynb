{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvXwyS263AMk"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Источник: https://github.com/NVIDIA/NeMo/blob/main/tutorials/asr/Online_Noise_Augmentation.ipynb\n",
        "\"\"\"\n",
        "\n",
        "## Установите зависимости\n",
        "!pip install wget\n",
        "!apt-get install sox libsndfile1 ffmpeg\n",
        "!pip install text-unidecode\n",
        "\n",
        "# ## Установите NeMo\n",
        "BRANCH = 'main'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[asr]\n",
        "\n",
        "## Установите TorchAudio\n",
        "!pip install torchaudio>=0.13.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "## Возьмите конфигурацию, которую мы будем использовать в этом примере\n",
        "!mkdir configs\n",
        "!pip install librosa==0.9.2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import librosa\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "import torch\n",
        "import IPython.display as ipd\n",
        "import soundfile as sf\n",
        "# Импорт компонента дополнения данных из коллекции ASR\n",
        "from nemo.collections.asr.parts.preprocessing import perturb, segment"
      ],
      "metadata": {
        "id": "tGfPBju4QexY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VAym0M7Vf6I_",
        "outputId": "1e839d5c-1281-4299-f9d2-aaec827a2f18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqg4Rwki4jBX"
      },
      "source": [
        "# Введение\n",
        "\n",
        "Аугументация данных является полезным методом для улучшения производительности моделей, который применим в различных областях. Некоторые дополнения могут также существенно улучшить устойчивость моделей к зашумленным выборкам. \n",
        "\n",
        "В этом блокноте мы описываем, как построить пайплайн аугументаций внутри [Neural Modules (NeMo)] (https://github.com/NVIDIA/NeMo).\n",
        "\n",
        "В блокноте будут описаны следующие шаги:\n",
        "\n",
        " - Подготовка набора данных: Подготовка набора данных шума с использованием файла примера.\n",
        "\n",
        " - Построение пайплайна аугументаций данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XieMEo84pJ-"
      },
      "source": [
        "## Примечание\n",
        "Аугументация данных важна для многих наборов данных, но это происходит за счет увеличения времени обучения, если выборки дополняются во время обучения. Некоторые аугументации являются особенно дорогостоящими с точки зрения того, сколько времени они занимают для обработки одной выборки. Вот несколько примеров медленных аугментаций, доступных в NeMo: \n",
        "\n",
        " - Возмущение скорости\n",
        " - Возмущение временной растяжки (уровень образца)\n",
        " - Шумовое возмущение\n",
        " - Импульсное возмущение\n",
        " - Аугментация растяжения времени (пакетный уровень, нейронный модуль)\n",
        " \n",
        "Для таких дополнений рекомендуется предварительно обработать набор данных в автономном режиме за единовременную стоимость предварительной обработки, а затем обучить набор данных на этом дополненном наборе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtLm_XuQ3pmk"
      },
      "outputs": [],
      "source": [
        "# Измените это, если вы не хотите, чтобы данные извлекались в текущий каталог.\n",
        "data_dir = '.'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for audio_path in glob.glob(\"/content/drive/MyDrive/SPbU_smart-assistant/raw/*.*\"):\n",
        "  sample, sr = librosa.core.load(audio_path)\n",
        "  sf.write(audio_path, sample, samplerate=sr)"
      ],
      "metadata": {
        "id": "C36EvBLAKfAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузите набор данных. Это займет несколько мгновений...\n",
        "print(\"******\")\n",
        "if not os.path.exists(\"./raw\"):\n",
        "  os.makedirs(\"./raw\")\n",
        "for audio_path in glob.glob(\"/content/drive/MyDrive/SPbU_smart-assistant/raw/*.*\"):\n",
        "  !cp -v $audio_path \"./raw\"\n",
        "print(\"Конец.\\n******\")"
      ],
      "metadata": {
        "id": "iDsYeHfXguAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD9bprV66Oai"
      },
      "source": [
        "# Пайплайн дополнения данных\n",
        "\n",
        "Построение пайплайна дополнения данных в NeMo так же просто, как составление вложенного словаря, который описывает две вещи: \n",
        "\n",
        "1) Вероятность возникновения этого дополнения - с помощью ключевого слова `prob` <br>\n",
        "2) Аргументы ключевых слов, необходимые для данного класса дополнений.\n",
        "\n",
        "Ниже мы покажем несколько примеров таких дополнений. Обратите внимание, что для того, чтобы отличить исходный образец от возмущенного, мы значительно преувеличиваем силу возмущения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8Bd8s3e6TeK"
      },
      "source": [
        "## Подготовка аудиофайла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK8uwpt16d6I",
        "outputId": "0ca0b7c1-3e07-4632-d5c9-180c7dfa1cc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'speed': nemo.collections.asr.parts.preprocessing.perturb.SpeedPerturbation,\n",
              " 'time_stretch': nemo.collections.asr.parts.preprocessing.perturb.TimeStretchPerturbation,\n",
              " 'gain': nemo.collections.asr.parts.preprocessing.perturb.GainPerturbation,\n",
              " 'silence': nemo.collections.asr.parts.preprocessing.perturb.SilencePerturbation,\n",
              " 'impulse': nemo.collections.asr.parts.preprocessing.perturb.ImpulsePerturbation,\n",
              " 'shift': nemo.collections.asr.parts.preprocessing.perturb.ShiftPerturbation,\n",
              " 'noise': nemo.collections.asr.parts.preprocessing.perturb.NoisePerturbation,\n",
              " 'white_noise': nemo.collections.asr.parts.preprocessing.perturb.WhiteNoisePerturbation,\n",
              " 'rir_noise_aug': nemo.collections.asr.parts.preprocessing.perturb.RirAndNoisePerturbation,\n",
              " 'transcode_aug': nemo.collections.asr.parts.preprocessing.perturb.TranscodePerturbation,\n",
              " 'random_segment': nemo.collections.asr.parts.preprocessing.perturb.RandomSegmentPerturbation}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Посмотрим доступные возмущения\n",
        "perturb.perturbation_types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP1VpkOA6nE-"
      },
      "source": [
        "### Получение исходного аудиофайла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj4DNMmZ6ktm"
      },
      "outputs": [],
      "source": [
        "example = \"/content/raw/Audio1.wav\"\n",
        "sample, sr = librosa.core.load(example)\n",
        "ipd.Audio(sample, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9mZNm296tNf"
      },
      "source": [
        "### Конвертировать в формат WAV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDjlgLc-6vtq"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "sf.write(example, sample, samplerate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEkV-ikT6xgB"
      },
      "outputs": [],
      "source": [
        "sample, sr = librosa.core.load(example)\n",
        "ipd.Audio(sample, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmuwEwIQ6zK3"
      },
      "outputs": [],
      "source": [
        "# NeMo имеет свой собственный класс поддержки для загрузки wav-файлов\n",
        "def load_audio(filepath) -> segment.AudioSegment:\n",
        "    sample_segment = segment.AudioSegment.from_file(filepath, target_sr=sr)\n",
        "    return sample_segment\n",
        "\n",
        "sample_segment = load_audio(example)\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTnf1g1y63wZ"
      },
      "source": [
        "## Возмущение белого шума\n",
        "\n",
        "Возмущение белого шума выполняется следующими шагами: <br>\n",
        "1) Случайная выборка амплитуды шума из равномерно распределенного диапазона (определенного в дБ) <br>\n",
        "2) Выборка гауссовского шума (mean  = 0, std  = 1) с той же длиной, что и аудиосигнал.<br>\n",
        "3) Масштабируйте этот гауссов шум по амплитуде (в дБ) <br>\n",
        "4) Добавьте этот вектор шума к исходному образцу.\n",
        "\n",
        "Примечательно, что исходный сигнал не должен иметь \"шипящего звука\", постоянно присутствующего в возмущенной версии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jaPQyUY65ij"
      },
      "outputs": [],
      "source": [
        "white_noise = perturb.WhiteNoisePerturbation(min_level=-50, max_level=-30)\n",
        "\n",
        "# Perturb the audio file\n",
        "sample_segment = load_audio(example)\n",
        "white_noise.perturb(sample_segment)\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kywA3h4T7G_S"
      },
      "source": [
        "## Возмущения, зависящие от данных\n",
        "\n",
        "Некоторые возмущения требуют внешнего источника данных для того, чтобы возмутить исходную выборку. Возмущение шумом - прекрасный пример одного из таких возмущений, для которого требуется внешний набор данных с источником шума, чтобы возмутить исходные данные."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYm2DgGQ7KPe"
      },
      "source": [
        "### Подготовка манифеста \"шумовых\" образцов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXZ1o85E7FLT"
      },
      "outputs": [],
      "source": [
        "# Lets prepare a manifest file using the baseline file itself, cut into 1 second segments\n",
        "\n",
        "def write_manifest(filepath, data_dir='.', manifest_name='noise_manifest', duration_max=1e9, duration_stride=1.0):\n",
        "              \n",
        "    with open(os.path.join(data_dir, manifest_name + '.json'), 'w') as fout:\n",
        "        y, sr = librosa.load(filepath)\n",
        "        duration = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "        offsets = []\n",
        "        durations = []\n",
        "\n",
        "        if duration > duration_max:\n",
        "            current_offset = 0.0\n",
        "\n",
        "            while current_offset < duration:\n",
        "                difference = duration - current_offset\n",
        "                segment_duration = min(duration_max, difference)\n",
        "\n",
        "                offsets.append(current_offset)\n",
        "                durations.append(segment_duration)\n",
        "\n",
        "                current_offset += duration_stride\n",
        "\n",
        "        else:\n",
        "            offsets.append(0.0)\n",
        "            durations.append(duration)\n",
        "\n",
        "\n",
        "        for duration, offset in zip(durations, offsets):\n",
        "            metadata = {\n",
        "                'audio_filepath': filepath,\n",
        "                'duration': duration,\n",
        "                'label': 'noise',\n",
        "                'text': '_',  # for compatibility with ASRAudioText collection\n",
        "                'offset': offset,\n",
        "            }\n",
        "\n",
        "            json.dump(metadata, fout)\n",
        "            fout.write('\\n')\n",
        "            fout.flush()\n",
        "\n",
        "        name = noise_path.split('/')[-1]\n",
        "        print(f\"Wrote {len(durations)} segments for filename {name}\")\n",
        "            \n",
        "    print(\"Finished preparing manifest !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLTT8jlP7NdU",
        "outputId": "9cbd30e4-7645-4625-cb61-5b0808e991f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/SPbU_smart-assistant/noises/1.wav' -> './noises/1.wav'\n",
            "'/content/drive/MyDrive/SPbU_smart-assistant/noises/2.wav' -> './noises/2.wav'\n",
            "'/content/drive/MyDrive/SPbU_smart-assistant/noises/3.wav' -> './noises/3.wav'\n",
            "'/content/drive/MyDrive/SPbU_smart-assistant/noises/4.wav' -> './noises/4.wav'\n",
            "'/content/drive/MyDrive/SPbU_smart-assistant/noises/5.wav' -> './noises/5.wav'\n",
            "'/content/drive/MyDrive/SPbU_smart-assistant/noises/6.wav' -> './noises/6.wav'\n",
            "'/content/drive/MyDrive/SPbU_smart-assistant/noises/7.wav' -> './noises/7.wav'\n"
          ]
        }
      ],
      "source": [
        "# Write a \"noise\" manifest file\n",
        "if not os.path.exists(\"./noises\"):\n",
        "  os.makedirs(\"./noises\")\n",
        "for audio_path in glob.glob(\"/content/drive/MyDrive/SPbU_smart-assistant/noises/*.*\"):\n",
        "  !cp -v $audio_path \"./noises\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"./manifests\"):\n",
        "  os.makedirs(\"./manifests\")\n",
        "\n",
        "for noise_path in glob.glob(\"/content/drive/MyDrive/SPbU_smart-assistant/noises/*.*\"):\n",
        "  noise_sample, noise_sr = librosa.core.load(noise_path)\n",
        "  sf.write(noise_path, noise_sample, samplerate=noise_sr)\n",
        "  noise_sample, noise_sr = librosa.core.load(noise_path)\n",
        "  name = noise_path.split('/')[-1][-5]\n",
        "  write_manifest(noise_path, data_dir='./manifests', manifest_name=f'noise_{name}s', duration_stride=1.0, duration_max=30.0)"
      ],
      "metadata": {
        "id": "n9Nk39BwX7GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izbdrSmd7PY5"
      },
      "outputs": [],
      "source": [
        "# Давайте прочитаем файл манифеста шума\n",
        "noise_manifest_path = '/content/manifests/noise_7s.json'\n",
        "\n",
        "!head -n 5 {noise_manifest_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV9ypBqz7V9a"
      },
      "source": [
        "## Возмущение шума\n",
        "\n",
        "Возмущение шума выполняется следующими шагами : <br>\n",
        "1) Случайная выборка шкалы амплитуды образца шума из равномерно распределенного диапазона (определенного в дБ) <br>\n",
        "2) Случайно выбирается аудиоклип из набора доступных образцов шума <br>\n",
        "3) Вычислите коэффициент усиления (в дБ), необходимый для шумового клипа по сравнению с исходным образцом, и масштабируйте шум по этому коэффициенту.<br>\n",
        "4) Если длительность шумового фрагмента меньше, чем длительность исходного аудио, то случайным образом выберите индекс во времени из исходного образца, куда будет добавлен шумовой фрагмент.<br>\n",
        "5) Если вместо этого шумовой фрагмент длиннее, чем длительность исходного аудио, то произвольно выделите шумовой фрагмент и добавьте полный фрагмент к исходному аудио. <br>\n",
        "\n",
        "Примечательно, что образец с шумовым возмущением должен звучать так, как будто одновременно воспроизводятся два звука (наложение звука) по сравнению с исходным сигналом. Величина шума зависит от шага (3), а место добавления шума - от шагов (4) и (5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjSXci1v7Tlg"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "rng = 42 #заметим, что вы можете использовать целое число в качестве случайной затравки для воспроизведения результата \n",
        "noise = perturb.NoisePerturbation(manifest_path=noise_manifest_path,\n",
        "                                  min_snr_db=-10, max_snr_db=-10,\n",
        "                                  max_gain_db=300.0, rng=rng)\n",
        "\n",
        "# Возмутить аудиофайл\n",
        "sample_segment = load_audio(example)\n",
        "noise.perturb(sample_segment)\n",
        "\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IreIbeHwFHPb"
      },
      "source": [
        "## RIR и шумовое возмущение\n",
        "Увеличение RIR с помощью аддитивного шума переднего плана и фона.\n",
        "В этой реализации аудиоданные дополняются сначала сверткой аудио с импульсной характеристикой помещения\n",
        "а затем добавляется шум переднего плана и фоновый шум при различных значениях SNR. RIR, шумы переднего плана и фоновые шумы\n",
        "должны поставляться либо в виде файла манифеста, либо в виде аудиофайлов в формате tarred (быстрее)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsvmOxPsFHPb"
      },
      "source": [
        "### Подготовьте данные rir и манифест"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/stable/scripts/dataset_processing/get_openslr_rir_data.py\"\n",
        "!wget --no-cache --backups=1 {url}"
      ],
      "metadata": {
        "id": "ts1JO2yyDo5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pwWe_GxFHPc"
      },
      "outputs": [],
      "source": [
        "# Это место, куда будут загружены данные rir.\n",
        "# Измените это, если вы не хотите, чтобы данные были извлечены в текущий каталог.\n",
        "rir_data_path = '.'\n",
        "!python get_openslr_rir_data.py --data_root {rir_data_path}\n",
        "rir_manifest_path = os.path.join(rir_data_path, 'processed', 'rir.json')\n",
        "!head -n 3 {rir_manifest_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stgPfGCCFHPc"
      },
      "source": [
        "### Создать экземпляр RIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdRDMwSRFHPc"
      },
      "outputs": [],
      "source": [
        "rir = perturb.RirAndNoisePerturbation(rir_manifest_path=rir_manifest_path, \n",
        "                                      rir_prob=1,\n",
        "                                      noise_manifest_paths=[noise_manifest_path], # используйте путь noise_manifest_path из предыдущего шага\n",
        "                                      bg_noise_manifest_paths=[noise_manifest_path],\n",
        "                                      min_snr_db=[20],# шум переднего плана snr\n",
        "                                      max_snr_db=[20],\n",
        "                                      bg_min_snr_db=[20], # фоновый шум snr\n",
        "                                      bg_max_snr_db=[20],\n",
        "                                      noise_tar_filepaths=[None],# `[None]` указывает, что шумовые аудиофайлы не являются tar.\n",
        "                                      bg_noise_tar_filepaths=[None])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7x3DMv6FHPc"
      },
      "source": [
        "### Возмущение звука"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe5BYJZOFHPc"
      },
      "outputs": [],
      "source": [
        "sample_segment = load_audio(example)\n",
        "rir.perturb(sample_segment)\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJjUkGJu7ern"
      },
      "source": [
        "## Возмущение скорости\n",
        "\n",
        "Возмущение скорости изменяет скорость речи, но не сохраняет высоту тона звука. Попробуйте несколько случайных возмущений, чтобы увидеть, как меняется высота тона при изменении длительности аудиофайла.\n",
        "\n",
        "**Примечание**: Это очень медленная аугментация, и ее не рекомендуется выполнять в режиме онлайн для больших наборов данных, так как это может значительно увеличить время обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ic-ziInU7ZKC"
      },
      "outputs": [],
      "source": [
        "resample_type = 'kaiser_best'  # Может быть ['kaiser_best', 'kaiser_fast', 'fft', 'scipy']\n",
        "speed = perturb.SpeedPerturbation(sr, resample_type, min_speed_rate=0.5, max_speed_rate=2.0, num_rates=-1)\n",
        "\n",
        "# Возмутить аудиофайл\n",
        "sample_segment = load_audio(example)\n",
        "speed.perturb(sample_segment)\n",
        "\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhHX3dyh7jPq"
      },
      "source": [
        "## Возмущение временной растяжки\n",
        "\n",
        "Возмущение Time Stretch изменяет скорость речи, а также сохраняет высоту тона звука. <br>\n",
        "Попробуйте несколько случайных возмущений, чтобы увидеть, как высота тона остается почти неизменной при изменении длительности аудиофайла."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_kNSfcK7lfP"
      },
      "source": [
        "### Примечание об оптимизации скорости\n",
        "\n",
        "Растягивание времени является дорогостоящим дополнением и может привести к резкому увеличению времени обучения. Предлагается установить библиотеку `numba` с помощью conda, чтобы использовать более оптимизированное ядро аугментации.\n",
        "\n",
        "```python\n",
        "conda install numba\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpeb0QUZ7g3l"
      },
      "outputs": [],
      "source": [
        "time_stretch = perturb.TimeStretchPerturbation(min_speed_rate=0.7, max_speed_rate=1.5, num_rates=3)\n",
        "\n",
        "# Возмутить аудиофайл\n",
        "sample_segment = load_audio(example)\n",
        "time_stretch.perturb(sample_segment)\n",
        "\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ImpulsePerturbation\n",
        "Convolves audio with a Room Impulse Response. <br>\n",
        "Args:\n",
        "*   manifest_path (list): Manifest file for RIRs\n",
        "*   shift_impulse (bool): Shift impulse response to adjust for delay at the beginning\n",
        "\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "SekyeVCOTTcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "impulse = perturb.ImpulsePerturbation(manifest_path=noise_manifest_path,shift_impulse=True)\n",
        "\n",
        "sample_segment = load_audio(example)\n",
        "impulse.perturb(sample_segment)\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ],
      "metadata": {
        "id": "L2TwdJIpUI1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhH1-Ga87rCX"
      },
      "source": [
        "# Конвейер дополнений\n",
        "\n",
        "Конвейер дополнений может быть построен несколькими способами, либо явно путем инстанцирования объектов этих возмущений, либо неявно путем предоставления аргументов этих дополнений в виде вложенного словаря.\n",
        "\n",
        "Мы покажем оба подхода в следующих разделах"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perturb.perturbation_types  # Доступные возмущения"
      ],
      "metadata": {
        "id": "5Jju_z-YZu6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwWE7swo72WP"
      },
      "source": [
        "### Устанавливаем возмущения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdLYn0hx7pRU"
      },
      "outputs": [],
      "source": [
        "perturbations = [\n",
        "    perturb.WhiteNoisePerturbation(min_level=-70, max_level=-45),\n",
        "    perturb.GainPerturbation(min_gain_dbfs=0, max_gain_dbfs=300),\n",
        "    perturb.NoisePerturbation(manifest_path=noise_manifest_path,\n",
        "                                min_snr_db=20, max_snr_db=10, max_gain_db=300.0)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDSSbZ8w7zzR"
      },
      "source": [
        "### Выберите вероятность применения возмущений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmoxfLSL7xPJ"
      },
      "outputs": [],
      "source": [
        "probas = [1.0, 1.0, 1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl0tnrMq79Jh"
      },
      "source": [
        "### Подготовьте объект аудио дополнения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO6T4U4f767o"
      },
      "outputs": [],
      "source": [
        "augmentations = list(zip(probas, perturbations))\n",
        "audio_augmentations = perturb.AudioAugmentor(augmentations)\n",
        "\n",
        "audio_augmentations._pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_segment = load_audio(example)\n",
        "audio_augmentations.perturb(sample_segment)\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ],
      "metadata": {
        "id": "3zc5HTRPEhzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/raw/Audio2.wav'\n",
        "sample_segment = load_audio(path)\n",
        "audio_augmentations.perturb(sample_segment)\n",
        "ipd.Audio(sample_segment.samples, rate=sr)"
      ],
      "metadata": {
        "id": "Pc7Hfad_IjNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probas = [1.0, 1.0, 1.0]\n",
        "for i in range(14):\n",
        "  perturbations = [\n",
        "    perturb.WhiteNoisePerturbation(min_level=-80, max_level=-40),\n",
        "    perturb.GainPerturbation(min_gain_dbfs=0, max_gain_dbfs=30),\n",
        "    perturb.NoisePerturbation(manifest_path=f'./manifests/noise_{i%7+1}s.json',\n",
        "                              min_snr_db=20, max_snr_db=10, max_gain_db=30.0)]\n",
        "\n",
        "  augmentations = list(zip(probas, perturbations))\n",
        "  audio_augmentations = perturb.AudioAugmentor(augmentations)\n",
        "\n",
        "  for path in glob.glob(\"./raw/*.*\"):\n",
        "    sample_segment = load_audio(path)\n",
        "    audio_augmentations.perturb(sample_segment)\n",
        "    name = path.split('/')[-1][:-4]\n",
        "\n",
        "    sf.write(f\"./drive/MyDrive/SPbU_smart-assistant/auto/{name}_{i}.wav\", \n",
        "             sample_segment.samples, samplerate=sr, subtype='PCM_24')"
      ],
      "metadata": {
        "id": "6izpJSORBb78"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}