{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff74bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-16 18:16:01 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-16 18:16:02 nemo_logging:349] /home/a.lokis/miniconda3/envs/asr_env/lib/python3.9/site-packages/torch/jit/annotations.py:299: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2022-12-16 18:16:03 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-16 18:16:04 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from jiwer import wer, cer\n",
    "\n",
    "import glob\n",
    "import subprocess\n",
    "import tarfile\n",
    "import wget\n",
    "import copy\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "from nemo.collections.asr.metrics.wer import word_error_rate\n",
    "from nemo.utils import logging, exp_manager\n",
    "from nemo.collections.nlp.models import PunctuationCapitalizationModel\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as ptl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a05b8",
   "metadata": {},
   "source": [
    "# LM model KenLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaea546",
   "metadata": {},
   "source": [
    "# Punctuation and Capitalization Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f53e196",
   "metadata": {},
   "source": [
    "dataset structure for CapPunkt model:\n",
    "\n",
    "data_for_CapPunkt/\n",
    "└── audio_PART.txt    - audio_filepath\n",
    "└── PART.txt          - target text\n",
    "└── text_PART.txt     - preprocessed text\n",
    "└── labels_PART.txt   - labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58276312",
   "metadata": {},
   "source": [
    "### Build config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807f3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trainer_and_model(restore_model_path=None):\n",
    "    \n",
    "    config_path = 'CapPunkt_configs/punctuation_capitalization_lexical_audio_config.yaml'\n",
    "    config = OmegaConf.load(config_path) \n",
    "\n",
    "    accelerator = 'gpu' \n",
    "    config.trainer.devices = [2]\n",
    "    config.trainer.accelerator = accelerator\n",
    "\n",
    "    config.trainer.max_epochs = 100\n",
    "\n",
    "    config.trainer.strategy = None\n",
    "    config.exp_dir = f'experiments/'\n",
    "    config.name = f\"LexicalCapPunkt-LexCapPunkt\"\n",
    "    config.checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "                                               monitor=\"val_loss\",\n",
    "                                               mode=\"min\",\n",
    "                                               always_save_nemo=True,\n",
    "                                               save_best_model=True),\n",
    "    config.exp_manager.create_wandb_logger = True\n",
    "    config.exp_manager.wandb_logger_kwargs = {'name': 'test_LCP',\n",
    "                                              'project': 'asr_experiments', \n",
    "                                              'log_model': 'all'}\n",
    "    config.exp_manager.explicit_log_dir='Punctuation_And_Capitalization_Lexical_Audio'\n",
    "\n",
    "    trainer = ptl.Trainer(**config.trainer)\n",
    "    \n",
    "    PRETRAINED_BERT_MODEL = \"bert-base-uncased\"\n",
    "    PRETRAINED_ASR_MODEL = 'stt_ru_quartznet15x5'\n",
    "\n",
    "    config.model.train_ds.ds_item = 'data_for_CapPunkt'\n",
    "    config.model.validation_ds.ds_item = 'data_for_CapPunkt'\n",
    "    config.model.test_ds.ds_item = 'data_for_CapPunkt' \n",
    "\n",
    "    config.model.language_model.pretrained_model_name = PRETRAINED_BERT_MODEL\n",
    "    config.model.train_ds.tokens_in_batch = 1024\n",
    "    config.model.train_ds.text_file = 'text_train.txt'\n",
    "    config.model.train_ds.labels_file = 'labels_train.txt'\n",
    "    config.model.train_ds.audio_file = 'audio_train.txt'\n",
    "    config.model.train_ds.num_workers = 32\n",
    "    config.model.validation_ds.tokens_in_batch = 1024\n",
    "    config.model.validation_ds.text_file = 'text_dev.txt'\n",
    "    config.model.validation_ds.labels_file = 'labels_dev.txt'\n",
    "    config.model.validation_ds.audio_file = 'audio_dev.txt'\n",
    "    config.model.validation_ds.num_workers = 32\n",
    "    config.model.test_ds.tokens_in_batch = 1024\n",
    "    config.model.test_ds.text_file = 'text_test.txt'\n",
    "    config.model.test_ds.labels_file = 'labels_test.txt'\n",
    "    config.model.test_ds.audio_file = 'audio_test.txt'\n",
    "    config.model.test_ds.num_workers = 32\n",
    "    config.model.optim.lr = 0.00002\n",
    "    config.model.audio_encoder.pretrained_model = PRETRAINED_ASR_MODEL\n",
    "    config.model.train_ds.preload_audios = True\n",
    "    config.model.validation_ds.preload_audios = True\n",
    "    config.model.test_ds.preload_audios = True\n",
    "    \n",
    "    if restore_model_path == None:\n",
    "#         config = OmegaConf.create(config)\n",
    "        model = nemo_nlp.models.PunctuationCapitalizationLexicalAudioModel(cfg=config.model, \n",
    "                                                                           trainer=trainer)\n",
    "    else:\n",
    "#         config = OmegaConf.create(config)\n",
    "        model = nemo_nlp.models.PunctuationCapitalizationLexicalAudioModel.restore_from(restore_model_path, \n",
    "                                                                                       trainer=trainer)\n",
    "        model.setup_test_data(config.model.test_ds)\n",
    "    \n",
    "    return trainer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce57591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer, model = build_trainer_and_model()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0835ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_to('NLP_models/LexCapPunkt100epochs.nemo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99fef02",
   "metadata": {},
   "source": [
    "### Test saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43ab312",
   "metadata": {},
   "source": [
    "5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb7c0f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78d212710cf452fb0df72bd013d3aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 12:28:10 punctuation_capitalization_model:333] Punctuation report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.42      98.33      97.87      66419\n",
      "    ! (label_id: 1)                                         46.53      17.18      25.09        390\n",
      "    , (label_id: 2)                                         78.98      69.86      74.14       5321\n",
      "    . (label_id: 3)                                         93.86      96.73      95.27       8385\n",
      "    ? (label_id: 4)                                         70.45      68.38      69.40        544\n",
      "    -------------------\n",
      "    micro avg                                               95.70      95.70      95.70      81059\n",
      "    macro avg                                               77.45      70.10      72.36      81059\n",
      "    weighted avg                                            95.42      95.70      95.51      81059\n",
      "    \n",
      "[NeMo I 2022-12-15 12:28:10 punctuation_capitalization_model:334] Capitalization report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         99.06      99.41      99.24      67274\n",
      "    U (label_id: 1)                                         97.08      95.40      96.24      13785\n",
      "    -------------------\n",
      "    micro avg                                               98.73      98.73      98.73      81059\n",
      "    macro avg                                               98.07      97.41      97.74      81059\n",
      "    weighted avg                                            98.72      98.73      98.73      81059\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_capit_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.73580932617188     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_capit_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     98.07246398925781     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_capit_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.40682220458984     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2501354560660227     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_punct_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     72.35643005371094     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_punct_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     77.44862365722656     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_punct_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     70.09593963623047     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_capit_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.73580932617188    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_capit_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.07246398925781    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_capit_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.40682220458984    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2501354560660227    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_punct_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    72.35643005371094    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_punct_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    77.44862365722656    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_punct_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    70.09593963623047    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.2501354560660227,\n",
       "  'test_punct_precision': 77.44862365722656,\n",
       "  'test_punct_f1': 72.35643005371094,\n",
       "  'test_punct_recall': 70.09593963623047,\n",
       "  'test_capit_precision': 98.07246398925781,\n",
       "  'test_capit_f1': 97.73580932617188,\n",
       "  'test_capit_recall': 97.40682220458984}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer, pretrained_model = build_trainer_and_model('NLP_models/LexCapPunkt5epochs.nemo')\n",
    "trainer.test(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442defc",
   "metadata": {},
   "source": [
    "20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b2f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 12:28:59 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmpuxbqgrah/35346f4f44504a64b606693320ef3afc_vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-12-15 12:29:03 modelPT:222] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-15 12:29:03 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    audio_file: audio_train.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: true\n",
      "    preload_audios: true\n",
      "    tokens_in_batch: 1024\n",
      "    max_seq_length: 512\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    \n",
      "[NeMo W 2022-12-15 12:29:03 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_test.txt\n",
      "    labels_file: labels_test.txt\n",
      "    audio_file: audio_test.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: false\n",
      "    preload_audios: true\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    tokens_in_batch: 1024\n",
      "    \n",
      "[NeMo W 2022-12-15 12:29:03 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    audio_file: audio_dev.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: false\n",
      "    preload_audios: true\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    \n",
      "[NeMo W 2022-12-15 12:29:03 nlp_overrides:229] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-12-15 12:29:08 modelPT:222] You tried to register an artifact under config key=language_model.config_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-15 12:29:08 modelPT:222] You tried to register an artifact under config key=class_labels.punct_labels_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-15 12:29:08 modelPT:222] You tried to register an artifact under config key=class_labels.capit_labels_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 12:29:08 cloud:56] Found existing object /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-15 12:29:08 cloud:62] Re-using file from: /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-15 12:29:08 common:912] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-12-15 12:29:08 cloud:56] Found existing object /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-15 12:29:08 cloud:62] Re-using file from: /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-15 12:29:08 common:912] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-15 12:29:09 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /raid/noneval.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ё\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 16\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-12-15 12:29:09 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /raid/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ё\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 12:29:09 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-15 12:29:10 save_restore_connector:243] Model EncDecCTCModel was successfully restored from /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-15 12:29:12 save_restore_connector:243] Model PunctuationCapitalizationLexicalAudioModel was successfully restored from /home/projects/asr/NLP_models/LexCapPunkt20epochs.nemo.\n",
      "[NeMo I 2022-12-15 12:29:17 punctuation_capitalization_dataset:1192] Features restored from data_for_CapPunkt/cached.__text_test.txt__labels_test.txt__.BertTokenizer.max_seq_length512.vocab30522.all_samples.punctuation_capitalization.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb3ae7ee6b24f8dba9654a59eab6610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 12:30:51 punctuation_capitalization_model:333] Punctuation report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.76      98.41      98.08      66419\n",
      "    ! (label_id: 1)                                         50.68      28.72      36.66        390\n",
      "    , (label_id: 2)                                         81.08      73.60      77.15       5321\n",
      "    . (label_id: 3)                                         94.37      97.14      95.73       8385\n",
      "    ? (label_id: 4)                                         74.86      71.69      73.24        544\n",
      "    -------------------\n",
      "    micro avg                                               96.13      96.13      96.13      81059\n",
      "    macro avg                                               79.75      73.91      76.17      81059\n",
      "    weighted avg                                            95.94      96.13      96.01      81059\n",
      "    \n",
      "[NeMo I 2022-12-15 12:30:51 punctuation_capitalization_model:334] Capitalization report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         99.13      99.49      99.31      67274\n",
      "    U (label_id: 1)                                         97.47      95.75      96.60      13785\n",
      "    -------------------\n",
      "    micro avg                                               98.86      98.86      98.86      81059\n",
      "    macro avg                                               98.30      97.62      97.96      81059\n",
      "    weighted avg                                            98.85      98.86      98.85      81059\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_capit_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.95774841308594     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_capit_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     98.30320739746094     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_capit_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.62031555175781     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3855004098316153     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_punct_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     76.17469787597656     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_punct_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     79.7488784790039      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_punct_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     73.90983581542969     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_capit_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.95774841308594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_capit_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.30320739746094    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_capit_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.62031555175781    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3855004098316153    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_punct_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    76.17469787597656    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_punct_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    79.7488784790039     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_punct_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    73.90983581542969    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.3855004098316153,\n",
       "  'test_punct_precision': 79.7488784790039,\n",
       "  'test_punct_f1': 76.17469787597656,\n",
       "  'test_punct_recall': 73.90983581542969,\n",
       "  'test_capit_precision': 98.30320739746094,\n",
       "  'test_capit_f1': 97.95774841308594,\n",
       "  'test_capit_recall': 97.62031555175781}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer, pretrained_model = build_trainer_and_model('NLP_models/LexCapPunkt20epochs.nemo')\n",
    "trainer.test(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "868dc4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 16:10:17 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmpq1907iqm/47aa42504e1542ab82a88528c590fff3_vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-12-15 16:10:21 modelPT:222] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-15 16:10:21 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    audio_file: audio_train.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: true\n",
      "    preload_audios: true\n",
      "    tokens_in_batch: 1024\n",
      "    max_seq_length: 512\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    \n",
      "[NeMo W 2022-12-15 16:10:21 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    audio_file: audio_dev.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: false\n",
      "    preload_audios: true\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    tokens_in_batch: 1024\n",
      "    \n",
      "[NeMo W 2022-12-15 16:10:21 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_test.txt\n",
      "    labels_file: labels_test.txt\n",
      "    audio_file: audio_test.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: false\n",
      "    preload_audios: true\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    tokens_in_batch: 1024\n",
      "    \n",
      "[NeMo W 2022-12-15 16:10:21 nlp_overrides:229] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-12-15 16:10:25 modelPT:222] You tried to register an artifact under config key=language_model.config_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-15 16:10:25 modelPT:222] You tried to register an artifact under config key=class_labels.punct_labels_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-15 16:10:25 modelPT:222] You tried to register an artifact under config key=class_labels.capit_labels_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 16:10:25 cloud:56] Found existing object /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-15 16:10:25 cloud:62] Re-using file from: /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-15 16:10:25 common:912] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-12-15 16:10:26 cloud:56] Found existing object /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-15 16:10:26 cloud:62] Re-using file from: /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-15 16:10:26 common:912] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-15 16:10:26 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /raid/noneval.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ё\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 16\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-12-15 16:10:26 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /raid/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ё\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 16:10:26 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-15 16:10:27 save_restore_connector:243] Model EncDecCTCModel was successfully restored from /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-15 16:10:31 save_restore_connector:243] Model PunctuationCapitalizationLexicalAudioModel was successfully restored from /home/projects/asr/NLP_models/LexCapPunkt10epochs.nemo.\n",
      "[NeMo I 2022-12-15 16:10:36 punctuation_capitalization_dataset:1192] Features restored from data_for_CapPunkt/cached.__text_test.txt__labels_test.txt__.BertTokenizer.max_seq_length512.vocab30522.all_samples.punctuation_capitalization.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8c1ad1f499487b9eb9939449e2fd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-15 16:12:55 punctuation_capitalization_model:333] Punctuation report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.79      98.24      98.02      66419\n",
      "    ! (label_id: 1)                                         49.05      26.41      34.33        390\n",
      "    , (label_id: 2)                                         79.26      74.05      76.56       5321\n",
      "    . (label_id: 3)                                         94.19      97.08      95.61       8385\n",
      "    ? (label_id: 4)                                         73.83      69.49      71.59        544\n",
      "    -------------------\n",
      "    micro avg                                               96.00      96.00      96.00      81059\n",
      "    macro avg                                               78.82      73.05      75.22      81059\n",
      "    weighted avg                                            95.81      96.00      95.88      81059\n",
      "    \n",
      "[NeMo I 2022-12-15 16:12:55 punctuation_capitalization_model:334] Capitalization report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         99.16      99.34      99.25      67274\n",
      "    U (label_id: 1)                                         96.77      95.92      96.34      13785\n",
      "    -------------------\n",
      "    micro avg                                               98.76      98.76      98.76      81059\n",
      "    macro avg                                               97.96      97.63      97.80      81059\n",
      "    weighted avg                                            98.76      98.76      98.76      81059\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_capit_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.79620361328125     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_capit_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.96492004394531     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_capit_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.6294174194336      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3256343603444133     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_punct_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     75.22386932373047     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_punct_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     78.82410430908203     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_punct_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     73.05257415771484     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_capit_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.79620361328125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_capit_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.96492004394531    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_capit_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.6294174194336     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3256343603444133    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_punct_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    75.22386932373047    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_punct_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    78.82410430908203    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_punct_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    73.05257415771484    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.3256343603444133,\n",
       "  'test_punct_precision': 78.82410430908203,\n",
       "  'test_punct_f1': 75.22386932373047,\n",
       "  'test_punct_recall': 73.05257415771484,\n",
       "  'test_capit_precision': 97.96492004394531,\n",
       "  'test_capit_f1': 97.79620361328125,\n",
       "  'test_capit_recall': 97.6294174194336}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer, pretrained_model = build_trainer_and_model('NLP_models/LexCapPunkt10epochs.nemo')\n",
    "trainer.test(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ca282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-16 17:16:28 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmpa5pi62o3/dce82fb4703f445d997b8014ea5075f3_vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-12-16 17:16:31 modelPT:222] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-16 17:16:32 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    audio_file: audio_train.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: true\n",
      "    preload_audios: true\n",
      "    tokens_in_batch: 1024\n",
      "    max_seq_length: 512\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    \n",
      "[NeMo W 2022-12-16 17:16:32 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    audio_file: audio_dev.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: false\n",
      "    preload_audios: true\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    tokens_in_batch: 1024\n",
      "    \n",
      "[NeMo W 2022-12-16 17:16:32 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_test.txt\n",
      "    labels_file: labels_test.txt\n",
      "    audio_file: audio_test.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: false\n",
      "    preload_audios: true\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    tokens_in_batch: 1024\n",
      "    \n",
      "[NeMo W 2022-12-16 17:16:32 nlp_overrides:229] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-12-16 17:16:36 modelPT:222] You tried to register an artifact under config key=language_model.config_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-16 17:16:36 modelPT:222] You tried to register an artifact under config key=class_labels.punct_labels_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-16 17:16:36 modelPT:222] You tried to register an artifact under config key=class_labels.capit_labels_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-16 17:16:36 cloud:56] Found existing object /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-16 17:16:36 cloud:62] Re-using file from: /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-16 17:16:36 common:912] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-12-16 17:16:36 cloud:56] Found existing object /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-16 17:16:36 cloud:62] Re-using file from: /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-16 17:16:36 common:912] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-16 17:16:37 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /raid/noneval.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ё\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 16\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-12-16 17:16:37 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /raid/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ё\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-16 17:16:37 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-16 17:16:38 save_restore_connector:243] Model EncDecCTCModel was successfully restored from /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-16 17:16:41 save_restore_connector:243] Model PunctuationCapitalizationLexicalAudioModel was successfully restored from /home/projects/asr/NLP_models/LexCapPunkt50epochs.nemo.\n",
      "[NeMo I 2022-12-16 17:16:44 punctuation_capitalization_dataset:1192] Features restored from data_for_CapPunkt/cached.__text_test.txt__labels_test.txt__.BertTokenizer.max_seq_length512.vocab30522.all_samples.punctuation_capitalization.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddd72b5efc647178e798480492e6471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-16 17:18:51 punctuation_capitalization_model:333] Punctuation report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.61      98.46      98.03      66419\n",
      "    ! (label_id: 1)                                         48.47      28.46      35.86        390\n",
      "    , (label_id: 2)                                         80.86      72.04      76.20       5321\n",
      "    . (label_id: 3)                                         94.44      96.99      95.70       8385\n",
      "    ? (label_id: 4)                                         75.89      66.54      70.91        544\n",
      "    -------------------\n",
      "    micro avg                                               96.02      96.02      96.02      81059\n",
      "    macro avg                                               79.45      72.50      75.34      81059\n",
      "    weighted avg                                            95.80      96.02      95.88      81059\n",
      "    \n",
      "[NeMo I 2022-12-16 17:18:51 punctuation_capitalization_model:334] Capitalization report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         99.03      99.55      99.29      67274\n",
      "    U (label_id: 1)                                         97.74      95.23      96.47      13785\n",
      "    -------------------\n",
      "    micro avg                                               98.81      98.81      98.81      81059\n",
      "    macro avg                                               98.38      97.39      97.88      81059\n",
      "    weighted avg                                            98.81      98.81      98.81      81059\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_capit_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.87837219238281     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_capit_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     98.38262176513672     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_capit_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.39103698730469     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3839734835710401     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_punct_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     75.34028625488281     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_punct_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     79.45431518554688     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_punct_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     72.49938201904297     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_capit_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.87837219238281    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_capit_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.38262176513672    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_capit_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.39103698730469    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3839734835710401    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_punct_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    75.34028625488281    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_punct_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    79.45431518554688    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_punct_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    72.49938201904297    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.3839734835710401,\n",
       "  'test_punct_precision': 79.45431518554688,\n",
       "  'test_punct_f1': 75.34028625488281,\n",
       "  'test_punct_recall': 72.49938201904297,\n",
       "  'test_capit_precision': 98.38262176513672,\n",
       "  'test_capit_f1': 97.87837219238281,\n",
       "  'test_capit_recall': 97.39103698730469}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer, pretrained_model = build_trainer_and_model('NLP_models/LexCapPunkt50epochs.nemo')\n",
    "trainer.test(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0b1c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-17 15:55:48 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmp6p76y2vf/45687d6462d34f2482e77c84653582a4_vocab.txt, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-12-17 15:55:52 modelPT:222] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-17 15:55:52 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    audio_file: audio_train.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: true\n",
      "    preload_audios: true\n",
      "    tokens_in_batch: 1024\n",
      "    max_seq_length: 512\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    \n",
      "[NeMo W 2022-12-17 15:55:52 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    audio_file: audio_dev.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: false\n",
      "    preload_audios: true\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    tokens_in_batch: 1024\n",
      "    \n",
      "[NeMo W 2022-12-17 15:55:52 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_tarred_dataset: false\n",
      "    ds_item: data_for_CapPunkt\n",
      "    text_file: text_test.txt\n",
      "    labels_file: labels_test.txt\n",
      "    audio_file: audio_test.txt\n",
      "    use_audio: true\n",
      "    use_bucketing: false\n",
      "    preload_audios: true\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 32\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    sample_rate: 16000\n",
      "    num_workers: 32\n",
      "    tokens_in_batch: 1024\n",
      "    \n",
      "[NeMo W 2022-12-17 15:55:52 nlp_overrides:229] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-12-17 15:55:56 modelPT:222] You tried to register an artifact under config key=language_model.config_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-17 15:55:56 modelPT:222] You tried to register an artifact under config key=class_labels.punct_labels_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-17 15:55:56 modelPT:222] You tried to register an artifact under config key=class_labels.capit_labels_file but an artifact for it has already been registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-17 15:55:56 cloud:56] Found existing object /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-17 15:55:56 cloud:62] Re-using file from: /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-17 15:55:56 common:912] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-12-17 15:55:57 cloud:56] Found existing object /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-17 15:55:57 cloud:62] Re-using file from: /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo\n",
      "[NeMo I 2022-12-17 15:55:57 common:912] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-17 15:55:58 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /raid/noneval.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ё\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 16\n",
      "    trim_silence: true\n",
      "    max_duration: 16.7\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-12-17 15:55:58 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /raid/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - ' '\n",
      "    - а\n",
      "    - б\n",
      "    - в\n",
      "    - г\n",
      "    - д\n",
      "    - е\n",
      "    - ё\n",
      "    - ж\n",
      "    - з\n",
      "    - и\n",
      "    - й\n",
      "    - к\n",
      "    - л\n",
      "    - м\n",
      "    - н\n",
      "    - о\n",
      "    - п\n",
      "    - р\n",
      "    - с\n",
      "    - т\n",
      "    - у\n",
      "    - ф\n",
      "    - х\n",
      "    - ц\n",
      "    - ч\n",
      "    - ш\n",
      "    - щ\n",
      "    - ъ\n",
      "    - ы\n",
      "    - ь\n",
      "    - э\n",
      "    - ю\n",
      "    - я\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-17 15:55:58 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-17 15:55:58 save_restore_connector:243] Model EncDecCTCModel was successfully restored from /home/a.lokis/.cache/torch/NeMo/NeMo_1.14.0/stt_ru_quartznet15x5/92506570b7206ea395e295b3fbbf07e3/stt_ru_quartznet15x5.nemo.\n",
      "[NeMo I 2022-12-17 15:56:02 save_restore_connector:243] Model PunctuationCapitalizationLexicalAudioModel was successfully restored from /home/projects/asr/NLP_models/LexCapPunkt100epochs.nemo.\n",
      "[NeMo I 2022-12-17 15:56:08 punctuation_capitalization_dataset:1192] Features restored from data_for_CapPunkt/cached.__text_test.txt__labels_test.txt__.BertTokenizer.max_seq_length512.vocab30522.all_samples.punctuation_capitalization.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363dcc0108474b3f875c2cfac62bbfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-17 15:58:12 punctuation_capitalization_model:333] Punctuation report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.47      98.42      97.94      66419\n",
      "    ! (label_id: 1)                                         35.67      30.00      32.59        390\n",
      "    , (label_id: 2)                                         80.28      70.55      75.10       5321\n",
      "    . (label_id: 3)                                         94.52      95.52      95.02       8385\n",
      "    ? (label_id: 4)                                         68.68      64.89      66.73        544\n",
      "    -------------------\n",
      "    micro avg                                               95.73      95.73      95.73      81059\n",
      "    macro avg                                               75.32      71.87      73.48      81059\n",
      "    weighted avg                                            95.54      95.73      95.61      81059\n",
      "    \n",
      "[NeMo I 2022-12-17 15:58:12 punctuation_capitalization_model:334] Capitalization report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         99.12      99.42      99.27      67274\n",
      "    U (label_id: 1)                                         97.11      95.68      96.39      13785\n",
      "    -------------------\n",
      "    micro avg                                               98.78      98.78      98.78      81059\n",
      "    macro avg                                               98.12      97.55      97.83      81059\n",
      "    weighted avg                                            98.78      98.78      98.78      81059\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_capit_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.8282470703125      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_capit_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     98.11518859863281     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_capit_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     97.54688262939453     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.34236304122560324    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_punct_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     73.47581481933594     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_punct_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     75.32382202148438     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test_punct_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      71.874755859375      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_capit_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.8282470703125     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_capit_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.11518859863281    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_capit_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    97.54688262939453    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.34236304122560324   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_punct_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    73.47581481933594    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_punct_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    75.32382202148438    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test_punct_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     71.874755859375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.34236304122560324,\n",
       "  'test_punct_precision': 75.32382202148438,\n",
       "  'test_punct_f1': 73.47581481933594,\n",
       "  'test_punct_recall': 71.874755859375,\n",
       "  'test_capit_precision': 98.11518859863281,\n",
       "  'test_capit_f1': 97.8282470703125,\n",
       "  'test_capit_recall': 97.54688262939453}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer, pretrained_model = build_trainer_and_model('NLP_models/LexCapPunkt100epochs.nemo')\n",
    "trainer.test(pretrained_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
